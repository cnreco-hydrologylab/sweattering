{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb482c90-0174-4d57-a7cf-d078d6a6c7a9",
   "metadata": {},
   "source": [
    "# S-2 image processing for NDVI retrieval from GEE\n",
    "This code is a semi-automatic routine for the download of NDVI values from Sentinel-2 via the Google Earth Engine API. The downloaded data represent the mean value of NDVI over an area of interest (AoI). The shape of the AoI must be provided manually into the code as a Java polygon or similar object.\n",
    "\n",
    "\n",
    "- The full timeseries of data is downloaded (from april 2017 to today).\n",
    "- All the images are reprojected with respect to the first one of the collection, that is the same as performing coregistration of all images.\n",
    "- A threshold-based mask for cloud covering is applied to the image such that any pixels with a probability value less than or equal to the value of the threshold will be kept, while all other pixels will be removed. The updated image with the applied mask is then returned. The threshold is user-defined by input.\n",
    "- The database of NDVI values is resampled to daily frequency and linearly interpolated.\n",
    "\n",
    "**Output**\n",
    "\n",
    "The output database has columns:\n",
    "- Date: timestamp of date and time of passage rounded at day.\n",
    "- NDVI: NDVI values, [dimensionless]. NDVI has range [-1,1]: negative values are related to clouds or water, positive small values (near 0) to bare soil, higher positive values to healthy vegetation.\n",
    "- Geometry: name of AoI.\n",
    "\n",
    "---\n",
    "**Dependencies** \n",
    "\n",
    "This code requires the installation of the Earth Engine API, `ee`. You can find more info on the installation procedure here: [Python installation of GEE](https://developers.google.com/earth-engine/guides/python_install). \\\n",
    "This code runs on browser-based notebooks only (Google Colaboratory, Jupyter Notebooks, etc...). \\\n",
    "Be aware that you won't need to install the Google Cloud APK to run the code.\n",
    "\n",
    "The full dependencies required are provided in the file of the environment google, `google.yml`. To install the virtual environment by using conda, run the lines below in the terminal after having activated `conda`.\n",
    "\n",
    "```python\n",
    "conda env create -f environment.yml # install environment from file environment.yml\n",
    "conda activate <myenv> # activate environment with name provided by header of .yml file\n",
    "conda info --envs # to check if everything worked fine\n",
    "```\n",
    "If you don't use `conda`, manually install the dependencies listed in the environment file by using `pip`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436f2941-013a-4dc1-b23c-c78bac1b3508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T09:58:11.026649973Z",
     "start_time": "2024-01-22T09:58:10.966730537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from funcs_gee import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55acb6ca-a823-4deb-80c6-0c2f6cca7ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T09:37:12.627275551Z",
     "start_time": "2024-01-22T09:37:12.618490958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract data\n",
    "\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60') # 60 m spat res TO0 BIG!!!\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
    "        qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    return image.updateMask(mask) \\\n",
    "                .select(\"B.*\") \\\n",
    "                .copyProperties(image, [\"system:time_start\"])\n",
    "\n",
    "def maskCloudPerc(image):\n",
    "    global thr\n",
    "    return image.updateMask(image.select('probability').lte(thr))\n",
    "\n",
    "def addNDVI(image:ee.Image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "def extract_NDVI(image:ee.Image):\n",
    "    \"\"\"Ausiliary function to extract data from an Image\n",
    "    \n",
    "    Optimal implementation is to map this function\n",
    "    on a whole ImageCollection via .map() and insert the\n",
    "    return into a ee.FeatureCollection.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    ee.Feature\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ndvi=image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    image=image.addBands(ndvi)\n",
    "    \n",
    "    mean = image.reduceRegion(**{ \n",
    "        'reducer': ee.Reducer.mean(),\n",
    "        'geometry': aoi,\n",
    "    })\n",
    "        \n",
    "    properties = {\n",
    "        'Date': image.get('system:time_start'), # only way to get a timestr is an external operation\n",
    "        'Geometry': geometry_title,\n",
    "        'NDVI': mean.get('NDVI'),\n",
    "    }\n",
    "    return ee.Feature(None, properties)\n",
    "\n",
    "\n",
    "def clean_date(date:int):\n",
    "    return time.strftime('%x %H', time.localtime((date)/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd5b597",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    " \n",
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902adf2f-f34c-47c7-b295-0a52cd43d458",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T09:34:00.059021503Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define area of interest. \n",
      "If you have a GeoJSON file, copy paste.\n",
      "If you have a KML, export to GeoJSON (plenty of free tools online).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide title for geometry:  big\n"
     ]
    }
   ],
   "source": [
    "print('Define area of interest. \\nIf you have a GeoJSON file, copy paste.\\n'+\n",
    "      'If you have a KML, export to GeoJSON (plenty of free tools online).')\n",
    "\n",
    "geoJSON = {\n",
    "\"type\": \"FeatureCollection\",\n",
    "\"name\": \"merged\",\n",
    "\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" } },\n",
    "\"features\": [\n",
    "{ \"type\": \"Feature\", \"properties\": { \"Name\": \"Budrio_campo_safe_half\", \"description\": None, \"tessellate\": 1 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ 11.53262979564736, 44.570842547510622 ], [ 11.532328100248961, 44.570445732016537 ], [ 11.53264162483709, 44.570339694294631 ], [ 11.532950828277439, 44.570738040751841 ] ] ] } } ] }\n",
    "\n",
    "nfeatures = len(geoJSON['features'])\n",
    "coords_geojson = [geoJSON['features'][i]['geometry']['coordinates'] for i in range(nfeatures)]\n",
    "geometry_title=input('Please provide title for geometry: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5985d6f115f197fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-22T09:34:01.764432967Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445bf0cf-b3f0-478d-9517-d8d6840eaaa4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-21T11:50:54.104110348Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# meters = cos(degree latitude) * (1852/60) * arc-seconds\n",
    "# 1 arcs = 1/3600 deg\n",
    "res_m=10\n",
    "coords_clean=coords_geojson[0][0]\n",
    "lon=np.unique([coords_clean[i][0] for i in range(len(coords_clean))])\n",
    "lat=np.unique([coords_clean[i][1] for i in range(len(coords_clean))])\n",
    "mean_lat=np.mean(lat)\n",
    "res_degs=res_m/(np.cos(np.deg2rad(mean_lat))*1852/60)/3600 #resolution in degrees\n",
    "\n",
    "lons=np.arange(min(lon), max(lon), res_degs)\n",
    "lats=np.arange(min(lat), max(lat), res_degs)\n",
    "lons_2d, lats_2d = np.meshgrid(lons, lats)\n",
    "lons_1d, lats_1d=[np.ravel(lons_2d), np.ravel(lats_2d)]\n",
    "id_2d=np.reshape(np.arange(len(np.ravel(lons_2d))), np.shape(lons_2d))\n",
    "\n",
    "points_dict={id: { 'id':id, 'coords':(lon, lat) } for id,lon,lat in zip(np.ravel(id_2d),lons_1d, lats_1d)}\n",
    "points_list=[ points_dict[id]['coords'] for id in points_dict]\n",
    "\n",
    "for id in points_dict:\n",
    "    p=points_dict[id]\n",
    "    lon=(p['coords'][0])\n",
    "    lat=(p['coords'][1])\n",
    "    area=[lon-res_degs, lat-res_degs, lon+res_degs, lat+res_degs]\n",
    "    p['area']=area\n",
    "    pixel=ee.Geometry.Rectangle(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7275ab81-f32c-4608-9a34-fcc41c25e352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T09:37:30.469745911Z",
     "start_time": "2024-01-22T09:37:30.449683120Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Filters definition\n",
    "# sp17 = ee.Filter.date('2017-04-04', '2017-05-22')\n",
    "# su17 = ee.Filter.date('2017-05-22', '2017-09-15')\n",
    "# au17 = ee.Filter.date('2017-09-15', '2017-11-02')\n",
    "tot17 = ee.Filter.date('2017-01-01', '2017-12-31')\n",
    "\n",
    "aoi = ee.Geometry.MultiPolygon(coords_geojson)\n",
    "\n",
    "# Get collection of images and filter\n",
    "s2 = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(aoi)\n",
    "        #.filter(tot17)\n",
    "        #.filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE',70))\n",
    "        .select(['B8', 'B4'])\n",
    "        .sort('system:time_start'))\n",
    "clouds = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        #.filter(tot17)\n",
    "        .sort('system:time_start'))\n",
    "s2 = s2.combine(clouds)\n",
    "\n",
    "# acq_times = img.aggregate_array('system:time_start').getInfo()\n",
    "# len([time.strftime('%x', time.gmtime(acq_time/1000)) for acq_time in acq_times])\n",
    "\n",
    "# To get all bands and infos of img collection, use\n",
    "# img.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3b30a7-3326-4aa0-ba39-e83d06183222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T09:37:27.740700339Z",
     "start_time": "2024-01-22T09:37:27.662195427Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Reprojection of images\n",
    "# This action is equivalent to performing coregistration of the images\n",
    "# to ensure that the coordinates are coherent in the whole collection\n",
    "\n",
    "proj=s2.first().projection();\n",
    "scale_mod=ee.Number(proj.nominalScale()).getInfo()\n",
    "trans_mod=proj.getInfo()['transform'];\n",
    "crs_mod=proj.getInfo()['crs'];\n",
    "\n",
    "s2 = s2.map(lambda image: image.reproject(crs_mod,trans_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee05290c-9fb2-4f25-9f37-5b62086569d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide threshold for cloud masking [number, int]. Ex. '50' corresponds to filtering out all images that have 50% or more of pixels that are flagged as covered by clouds. 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check data extraction: if something is printed below and has reasonable values, everything is ok (note: date is in a Matlab-like numeric, weird format, don't worry.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Date': 1493028680576, 'Geometry': 'big', 'NDVI': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clouds filtering\n",
    "thr = 100-int(input('Please provide threshold for cloud masking [number, int]. Ex. \\'50\\' corresponds to filtering out all images that have 50% or more of pixels that are flagged as covered by clouds.'))\n",
    "s2_filt = s2.map(maskCloudPerc)\n",
    "\n",
    "# Add NDVI and extract data\n",
    "aoi=pixel\n",
    "data = ee.FeatureCollection(s2_filt.map(extract_NDVI))\n",
    "data_out = data.getInfo()\n",
    "data_out_to_df = [e.get('properties') for e in data_out.get('features')]\n",
    "print('\\nCheck data extraction: if something is printed below and has reasonable values, everything is ok (note: date is in a Matlab-like numeric, weird format, don\\'t worry.)'); data_out_to_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac2798e-a8ca-4936-8b35-47c0092a5e35",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1874\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1874\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/ops.py:877\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 877\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:2380\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2380\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2381\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2382\u001b[0m     )\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/series.py:6225\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6217\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6223\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6224\u001b[0m ):\n\u001b[0;32m-> 6225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/series.py:6133\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6132\u001b[0m     )\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/nanops.py:1693\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'bigbig' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(data_out_to_df)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mDate \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mDate\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : pd\u001b[38;5;241m.\u001b[39mTimestamp(pd\u001b[38;5;241m.\u001b[39mto_datetime(clean_date(x))))\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# df['Data'] = df.Date.apply(lambda x : pd.Timestamp(x.date()))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:2378\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2372\u001b[0m         grouped_mean,\n\u001b[1;32m   2373\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2374\u001b[0m         engine_kwargs,\n\u001b[1;32m   2375\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2376\u001b[0m     )\n\u001b[1;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1929\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1931\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/internals/managers.py:1428\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1428\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/internals/blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1926\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1926\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/thesis-codes/conda/envs/google_libraries_libraries/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1878\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m   1881\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data_out_to_df)\n",
    "df.Date = df.Date.apply(lambda x : pd.Timestamp(pd.to_datetime(clean_date(x))))\n",
    "df = df.groupby('Date',as_index=False).mean()\n",
    "# df['Data'] = df.Date.apply(lambda x : pd.Timestamp(x.date()))\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76d8b1-f99e-4803-a90a-2663106cb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.loc['2020'].NDVI, marker='o',linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb27c25-ee22-42fa-add4-0e464e2049aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = df.resample('D').asfreq().interpolate(method='linear'); df_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366079f7-461c-42b1-a154-f62da105e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_daily)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739123e5-8c38-4ad5-8b54-70a434255b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_interp = True if input('Want to resample at a hourly frequency and interpolate values? [y/n]')=='y' else False\n",
    "if opt_interp:\n",
    "    df = df.resample('1H').asfreq().interpolate(method='linear').resample('D').mean()\n",
    "df['Geometry'] = geometry_title\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3324346-585d-4290-b82b-3816a632d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.NDVI); plt.title('NDVI timeseries - 2017 to today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a0e26-6b3c-4ba7-aaf1-767b6bd143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = input(\"Wanna save in Data directory? [y/n] \")\n",
    "if save=='y':\n",
    "    opt_name = input('Please provide name of file, without extension: [default: geometry-name_NDVI]')\n",
    "    if opt_name=='': opt_name=geometry_title+'_NDVI'\n",
    "    df.to_csv(f'..\\\\..\\\\Data\\\\{opt_name}.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "610f9cca-f20c-46c9-9502-4881ac48df42",
   "metadata": {},
   "source": [
    "plt.scatter(df.NDVI, df_not_proj.NDVI)\n",
    "plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))\n",
    "\n",
    "def Rvalue(x:list,y:list)->float:\n",
    "    \"\"\"compute Pearson's R between x,y data\"\"\"\n",
    "    if len(x)!=len(y):\n",
    "        raise ValueError(\n",
    "            f'x and y must have same first dimension,'+\n",
    "            'but have shapes{np.shape(x)} and {np.shape(y)}')\n",
    "        \n",
    "    matrix = np.array( \n",
    "        [ [x[i], y[i]] for i in range(len(x))\n",
    "         if not (np.isnan(x[i])and(np.isnan(y[i]))) ] )\n",
    "    return np.corrcoef(matrix,rowvar=False)[0][1]\n",
    "\n",
    "R = Rvalue(df.NDVI, df_not_proj.NDVI)\n",
    "plt.title('NDVI reprojected (x) VS not reproj (y) ')\n",
    "t = plt.text(0.5, 0.1,\n",
    "             r'$R^2$ = '+f'{R**2:.3f}',\n",
    "             ha=\"center\", va=\"center\", size=15,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"tab:orange\", ec=\"k\", lw=2, alpha=.5))\n",
    "plt.savefig('scatter_NDVI_reproj-VS-not.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebdd34-209a-4007-ad99-2090b50cbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time range.\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Define your geometry, with coordinates [lon_min, lat_min, lon_max, lat_max]\n",
    "region_name = 'region'\n",
    "coords = [11.532328100248961, 44.570339694294631, 11.532950828277439 , 44.570738040751841]\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "import ee\n",
    "import datetime as dt\n",
    "\n",
    "# Function to calculate NDVI.\n",
    "def addNDVI(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)\n",
    "\n",
    "\n",
    "# Initialize the Earth Engine module.\n",
    "ee.Initialize()\n",
    "\n",
    "region = ee.Geometry.Rectangle(coords)\n",
    "\n",
    "# Load the Sentinel-2 SR Harmonized collection.\n",
    "s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(region)\n",
    "\n",
    "proj=s2.first().select('B2').projection()\n",
    "scale_mod=ee.Number(proj.nominalScale()).getInfo()\n",
    "trans_mod=proj.getInfo()['transform']\n",
    "crs_mod=proj.getInfo()['crs']\n",
    "\n",
    "# Update masks/add bands over the collection.\n",
    "s2_ndvi = s2.map(addNDVI)\n",
    "\n",
    "# Get pixels in the region with all bands, lon, lat and time\n",
    "ndvi = np.array(s2_ndvi.getRegion(region, scale_mod).getInfo())\n",
    "\n",
    "# Build dataframe and clean timestamps\n",
    "ndvi_df = pd.DataFrame(ndvi[1:], columns=ndvi[0])\n",
    "ndvi_df['datetime'] = [dt.datetime.fromtimestamp(ts).strftime(\"%Y-%m-%d %H:%M\") for ts in ndvi_df['time']/1000]\n",
    "drop_columns=['AOT', 'WVP', 'SCL', 'TCI_R', 'TCI_G', 'TCI_B', 'MSK_CLDPRB', 'MSK_SNWPRB', 'QA10', 'QA20', 'QA60','id','time']\n",
    "ndvi_df.drop(drop_columns, axis=1, inplace=True)\n",
    "ndvi_df=ndvi_df.set_index('datetime')\n",
    "\n",
    "answ=input('Save csv file? [[y]/n]')\n",
    "if answ=='y' or answ=='':\n",
    "    ndvi_df.to_csv(f'NDVI_{start_date}_{end_date}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
